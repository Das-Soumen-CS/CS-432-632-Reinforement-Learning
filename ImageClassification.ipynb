{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "c7a7b177-da5f-4c2c-a22d-0e20e57bbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils ,layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "d2851045-d3fb-43d5-887e-00b933979db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Error reading notMNIST_small\\A\\.ipynb_checkpoints: [Errno 13] Permission denied: 'notMNIST_small\\\\A\\\\.ipynb_checkpoints'\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Error reading notMNIST_small\\F\\.ipynb_checkpoints: [Errno 13] Permission denied: 'notMNIST_small\\\\F\\\\.ipynb_checkpoints'\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "path='notMNIST_small'\n",
    "\n",
    "# Reading Images and storing each pixel in Images Matrix\n",
    "# Storing the corresponding labels in Labels Array\n",
    "for label in os.listdir(path):\n",
    "    label_path = os.path.join(path, label)\n",
    "    \n",
    "    if os.path.isdir(label_path):\n",
    "        label_idx = ord(label) - ord('A')\n",
    "        print(label_idx)\n",
    "        for image_file_path in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file_path)\n",
    "            \n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(label_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "c66f8bbf-a71e-4795-b102-1c4a36b73e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of Images = 18723\n",
      "No of Class_Label= 10\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no of Images =\",len(labels))\n",
    "#print(images.shape)\n",
    "print(\"No of Class_Label=\",label_idx+1)\n",
    "images=np.array(images)/255.0\n",
    "labels=utils.to_categorical(np.array(labels),num_classes=10)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "2e4311d1-244d-4143-be46-03d92df111f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "85b0c1fc-37e6-4cfb-a93e-09d5aa2bf484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plot the first image in the dataset\n",
    "plt.imshow(X_train[1])\n",
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "9b0123ad-d0db-4b7d-9c85-e3a10353dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845bb99-6df7-4ad5-91a0-45c739aaa737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_55 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567434 (2.16 MB)\n",
      "Trainable params: 567434 (2.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.5358 - accuracy: 0.8367 - val_loss: 0.4014 - val_accuracy: 0.8798\n",
      "Epoch 2/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.3244 - accuracy: 0.9030 - val_loss: 0.3317 - val_accuracy: 0.9065\n",
      "Epoch 3/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.2696 - accuracy: 0.9204 - val_loss: 0.3232 - val_accuracy: 0.9132\n",
      "Epoch 4/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.2233 - accuracy: 0.9326 - val_loss: 0.3104 - val_accuracy: 0.9206\n",
      "Epoch 5/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1877 - accuracy: 0.9441 - val_loss: 0.4071 - val_accuracy: 0.9166\n",
      "Epoch 6/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1707 - accuracy: 0.9507 - val_loss: 0.4196 - val_accuracy: 0.9072\n",
      "Epoch 7/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1518 - accuracy: 0.9530 - val_loss: 0.5058 - val_accuracy: 0.9079\n",
      "Epoch 8/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1375 - accuracy: 0.9579 - val_loss: 0.4817 - val_accuracy: 0.9219\n",
      "Epoch 9/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1328 - accuracy: 0.9602 - val_loss: 0.4715 - val_accuracy: 0.9139\n",
      "Epoch 10/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1215 - accuracy: 0.9659 - val_loss: 0.6517 - val_accuracy: 0.9025\n",
      "Epoch 11/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1104 - accuracy: 0.9666 - val_loss: 0.5262 - val_accuracy: 0.9272\n",
      "Epoch 12/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1061 - accuracy: 0.9689 - val_loss: 0.6300 - val_accuracy: 0.9179\n",
      "Epoch 13/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.1043 - accuracy: 0.9703 - val_loss: 0.6430 - val_accuracy: 0.9152\n",
      "Epoch 14/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.1067 - accuracy: 0.9726 - val_loss: 0.6582 - val_accuracy: 0.9139\n",
      "Epoch 15/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0942 - accuracy: 0.9741 - val_loss: 0.7051 - val_accuracy: 0.9186\n",
      "Epoch 16/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.1021 - accuracy: 0.9739 - val_loss: 0.7106 - val_accuracy: 0.9232\n",
      "Epoch 17/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0886 - accuracy: 0.9760 - val_loss: 0.7480 - val_accuracy: 0.9105\n",
      "Epoch 18/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0889 - accuracy: 0.9763 - val_loss: 0.7563 - val_accuracy: 0.9219\n",
      "Epoch 19/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0842 - accuracy: 0.9779 - val_loss: 1.0394 - val_accuracy: 0.9166\n",
      "Epoch 20/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0802 - accuracy: 0.9785 - val_loss: 0.8969 - val_accuracy: 0.9226\n",
      "Epoch 21/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0795 - accuracy: 0.9792 - val_loss: 0.9199 - val_accuracy: 0.9252\n",
      "Epoch 22/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0752 - accuracy: 0.9808 - val_loss: 0.9448 - val_accuracy: 0.9266\n",
      "Epoch 23/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0803 - accuracy: 0.9795 - val_loss: 0.8736 - val_accuracy: 0.9239\n",
      "Epoch 24/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0698 - accuracy: 0.9832 - val_loss: 0.9197 - val_accuracy: 0.9179\n",
      "Epoch 25/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.9851 - val_loss: 1.4548 - val_accuracy: 0.9099\n",
      "Epoch 26/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0702 - accuracy: 0.9830 - val_loss: 1.1850 - val_accuracy: 0.9192\n",
      "Epoch 27/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0735 - accuracy: 0.9834 - val_loss: 1.2615 - val_accuracy: 0.9146\n",
      "Epoch 28/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0680 - accuracy: 0.9841 - val_loss: 1.2009 - val_accuracy: 0.9152\n",
      "Epoch 29/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0786 - accuracy: 0.9833 - val_loss: 1.2456 - val_accuracy: 0.9105\n",
      "Epoch 30/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0573 - accuracy: 0.9855 - val_loss: 1.0129 - val_accuracy: 0.9206\n",
      "Epoch 31/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.9846 - val_loss: 1.6124 - val_accuracy: 0.9246\n",
      "Epoch 32/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0567 - accuracy: 0.9858 - val_loss: 1.3521 - val_accuracy: 0.9206\n",
      "Epoch 33/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0623 - accuracy: 0.9862 - val_loss: 1.3609 - val_accuracy: 0.9239\n",
      "Epoch 34/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0590 - accuracy: 0.9857 - val_loss: 1.1684 - val_accuracy: 0.9279\n",
      "Epoch 35/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0617 - accuracy: 0.9872 - val_loss: 1.1920 - val_accuracy: 0.9192\n",
      "Epoch 36/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0484 - accuracy: 0.9879 - val_loss: 1.2979 - val_accuracy: 0.9286\n",
      "Epoch 37/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0486 - accuracy: 0.9905 - val_loss: 1.2893 - val_accuracy: 0.9226\n",
      "Epoch 38/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0501 - accuracy: 0.9884 - val_loss: 1.1806 - val_accuracy: 0.9219\n",
      "Epoch 39/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0559 - accuracy: 0.9882 - val_loss: 1.6436 - val_accuracy: 0.9159\n",
      "Epoch 40/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0594 - accuracy: 0.9881 - val_loss: 1.3456 - val_accuracy: 0.9239\n",
      "Epoch 41/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0487 - accuracy: 0.9898 - val_loss: 1.3417 - val_accuracy: 0.9232\n",
      "Epoch 42/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0581 - accuracy: 0.9888 - val_loss: 1.9441 - val_accuracy: 0.9192\n",
      "Epoch 43/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0698 - accuracy: 0.9872 - val_loss: 1.6227 - val_accuracy: 0.9186\n",
      "Epoch 44/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0599 - accuracy: 0.9877 - val_loss: 1.5333 - val_accuracy: 0.9259\n",
      "Epoch 45/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.9899 - val_loss: 1.5816 - val_accuracy: 0.9232\n",
      "Epoch 46/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0626 - accuracy: 0.9883 - val_loss: 1.1795 - val_accuracy: 0.9266\n",
      "Epoch 47/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.9898 - val_loss: 1.5044 - val_accuracy: 0.9212\n",
      "Epoch 48/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0472 - accuracy: 0.9902 - val_loss: 1.4618 - val_accuracy: 0.9219\n",
      "Epoch 49/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0488 - accuracy: 0.9909 - val_loss: 1.7871 - val_accuracy: 0.9132\n",
      "Epoch 50/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0572 - accuracy: 0.9903 - val_loss: 1.4933 - val_accuracy: 0.9226\n",
      "Epoch 51/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0580 - accuracy: 0.9899 - val_loss: 1.6018 - val_accuracy: 0.9219\n",
      "Epoch 52/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.9903 - val_loss: 1.7206 - val_accuracy: 0.9319\n",
      "Epoch 53/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0505 - accuracy: 0.9908 - val_loss: 1.6324 - val_accuracy: 0.9279\n",
      "Epoch 54/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0481 - accuracy: 0.9918 - val_loss: 1.4484 - val_accuracy: 0.9252\n",
      "Epoch 55/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0489 - accuracy: 0.9914 - val_loss: 1.6722 - val_accuracy: 0.9266\n",
      "Epoch 56/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0441 - accuracy: 0.9910 - val_loss: 2.1803 - val_accuracy: 0.9186\n",
      "Epoch 57/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9911 - val_loss: 1.6898 - val_accuracy: 0.9199\n",
      "Epoch 58/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0589 - accuracy: 0.9907 - val_loss: 1.7885 - val_accuracy: 0.9226\n",
      "Epoch 59/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0561 - accuracy: 0.9894 - val_loss: 1.6829 - val_accuracy: 0.9252\n",
      "Epoch 60/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9913 - val_loss: 1.6924 - val_accuracy: 0.9292\n",
      "Epoch 61/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9913 - val_loss: 1.5855 - val_accuracy: 0.9272\n",
      "Epoch 62/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0560 - accuracy: 0.9901 - val_loss: 1.8874 - val_accuracy: 0.9186\n",
      "Epoch 63/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9919 - val_loss: 1.7932 - val_accuracy: 0.9259\n",
      "Epoch 64/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0562 - accuracy: 0.9918 - val_loss: 1.9033 - val_accuracy: 0.9232\n",
      "Epoch 65/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9917 - val_loss: 1.9831 - val_accuracy: 0.9219\n",
      "Epoch 66/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9927 - val_loss: 2.2301 - val_accuracy: 0.9239\n",
      "Epoch 67/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.9919 - val_loss: 2.0337 - val_accuracy: 0.9266\n",
      "Epoch 68/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0370 - accuracy: 0.9932 - val_loss: 2.0976 - val_accuracy: 0.9312\n",
      "Epoch 69/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0421 - accuracy: 0.9930 - val_loss: 2.6915 - val_accuracy: 0.9199\n",
      "Epoch 70/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9925 - val_loss: 2.0001 - val_accuracy: 0.9226\n",
      "Epoch 71/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0354 - accuracy: 0.9934 - val_loss: 2.1241 - val_accuracy: 0.9306\n",
      "Epoch 72/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0530 - accuracy: 0.9920 - val_loss: 1.9728 - val_accuracy: 0.9252\n",
      "Epoch 73/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0489 - accuracy: 0.9920 - val_loss: 2.0081 - val_accuracy: 0.9226\n",
      "Epoch 74/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9946 - val_loss: 2.2156 - val_accuracy: 0.9252\n",
      "Epoch 75/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9930 - val_loss: 2.2613 - val_accuracy: 0.9266\n",
      "Epoch 76/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0266 - accuracy: 0.9951 - val_loss: 2.3833 - val_accuracy: 0.9226\n",
      "Epoch 77/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9941 - val_loss: 2.5627 - val_accuracy: 0.9206\n",
      "Epoch 78/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 2.0505 - val_accuracy: 0.9286\n",
      "Epoch 79/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0267 - accuracy: 0.9955 - val_loss: 2.2914 - val_accuracy: 0.9259\n",
      "Epoch 80/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 0.9950 - val_loss: 2.2907 - val_accuracy: 0.9299\n",
      "Epoch 81/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0331 - accuracy: 0.9948 - val_loss: 2.4743 - val_accuracy: 0.9239\n",
      "Epoch 82/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9954 - val_loss: 2.1497 - val_accuracy: 0.9226\n",
      "Epoch 83/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 2.4064 - val_accuracy: 0.9259\n",
      "Epoch 84/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9947 - val_loss: 2.5565 - val_accuracy: 0.9166\n",
      "Epoch 85/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0324 - accuracy: 0.9944 - val_loss: 2.4505 - val_accuracy: 0.9259\n",
      "Epoch 86/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: 2.5420 - val_accuracy: 0.9239\n",
      "Epoch 87/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9941 - val_loss: 2.2571 - val_accuracy: 0.9186\n",
      "Epoch 88/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9935 - val_loss: 2.7818 - val_accuracy: 0.9219\n",
      "Epoch 89/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9958 - val_loss: 2.6761 - val_accuracy: 0.9206\n",
      "Epoch 90/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0342 - accuracy: 0.9951 - val_loss: 2.1157 - val_accuracy: 0.9292\n",
      "Epoch 91/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9938 - val_loss: 2.4550 - val_accuracy: 0.9239\n",
      "Epoch 92/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9955 - val_loss: 2.3107 - val_accuracy: 0.9252\n",
      "Epoch 93/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0300 - accuracy: 0.9953 - val_loss: 2.4638 - val_accuracy: 0.9266\n",
      "Epoch 94/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0353 - accuracy: 0.9944 - val_loss: 2.2063 - val_accuracy: 0.9199\n",
      "Epoch 95/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 0.9940 - val_loss: 2.4822 - val_accuracy: 0.9279\n",
      "Epoch 96/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0320 - accuracy: 0.9942 - val_loss: 2.4235 - val_accuracy: 0.9312\n",
      "Epoch 97/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9957 - val_loss: 2.6033 - val_accuracy: 0.9306\n",
      "Epoch 98/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0252 - accuracy: 0.9961 - val_loss: 2.8065 - val_accuracy: 0.9266\n",
      "Epoch 99/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0398 - accuracy: 0.9956 - val_loss: 2.8335 - val_accuracy: 0.9272\n",
      "Epoch 100/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 2.4801 - val_accuracy: 0.9292\n",
      "Epoch 101/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0294 - accuracy: 0.9953 - val_loss: 2.4614 - val_accuracy: 0.9266\n",
      "Epoch 102/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9953 - val_loss: 2.7225 - val_accuracy: 0.9232\n",
      "Epoch 103/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 2.5642 - val_accuracy: 0.9279\n",
      "Epoch 104/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9962 - val_loss: 2.2084 - val_accuracy: 0.9266\n",
      "Epoch 105/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9965 - val_loss: 2.0286 - val_accuracy: 0.9246\n",
      "Epoch 106/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 2.4231 - val_accuracy: 0.9266\n",
      "Epoch 107/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0294 - accuracy: 0.9968 - val_loss: 2.4162 - val_accuracy: 0.9306\n",
      "Epoch 108/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 2.5873 - val_accuracy: 0.9272\n",
      "Epoch 109/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9965 - val_loss: 2.4284 - val_accuracy: 0.9272\n",
      "Epoch 110/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9958 - val_loss: 2.3373 - val_accuracy: 0.9206\n",
      "Epoch 111/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9966 - val_loss: 3.1414 - val_accuracy: 0.9252\n",
      "Epoch 112/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0264 - accuracy: 0.9955 - val_loss: 2.6170 - val_accuracy: 0.9239\n",
      "Epoch 113/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9961 - val_loss: 2.4703 - val_accuracy: 0.9239\n",
      "Epoch 114/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0280 - accuracy: 0.9948 - val_loss: 2.6915 - val_accuracy: 0.9272\n",
      "Epoch 115/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0325 - accuracy: 0.9958 - val_loss: 2.6556 - val_accuracy: 0.9266\n",
      "Epoch 116/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 2.4800 - val_accuracy: 0.9259\n",
      "Epoch 117/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0310 - accuracy: 0.9949 - val_loss: 2.5984 - val_accuracy: 0.9246\n",
      "Epoch 118/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9962 - val_loss: 3.1467 - val_accuracy: 0.9226\n",
      "Epoch 119/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0264 - accuracy: 0.9961 - val_loss: 2.8396 - val_accuracy: 0.9219\n",
      "Epoch 120/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9958 - val_loss: 2.9145 - val_accuracy: 0.9212\n",
      "Epoch 121/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9958 - val_loss: 3.0272 - val_accuracy: 0.9232\n",
      "Epoch 122/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0236 - accuracy: 0.9967 - val_loss: 2.8000 - val_accuracy: 0.9252\n",
      "Epoch 123/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0279 - accuracy: 0.9966 - val_loss: 2.8562 - val_accuracy: 0.9259\n",
      "Epoch 124/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0192 - accuracy: 0.9966 - val_loss: 2.9654 - val_accuracy: 0.9246\n",
      "Epoch 125/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0180 - accuracy: 0.9974 - val_loss: 2.9304 - val_accuracy: 0.9259\n",
      "Epoch 126/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9967 - val_loss: 3.0995 - val_accuracy: 0.9226\n",
      "Epoch 127/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0189 - accuracy: 0.9967 - val_loss: 2.7182 - val_accuracy: 0.9259\n",
      "Epoch 128/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 2.8127 - val_accuracy: 0.9272\n",
      "Epoch 129/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9957 - val_loss: 3.4181 - val_accuracy: 0.9266\n",
      "Epoch 130/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 3.8129 - val_accuracy: 0.9219\n",
      "Epoch 131/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9971 - val_loss: 3.4153 - val_accuracy: 0.9206\n",
      "Epoch 132/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9961 - val_loss: 2.7151 - val_accuracy: 0.9212\n",
      "Epoch 133/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9967 - val_loss: 2.7141 - val_accuracy: 0.9192\n",
      "Epoch 134/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9969 - val_loss: 3.2060 - val_accuracy: 0.9246\n",
      "Epoch 135/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0281 - accuracy: 0.9963 - val_loss: 2.7463 - val_accuracy: 0.9279\n",
      "Epoch 136/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0331 - accuracy: 0.9956 - val_loss: 3.2497 - val_accuracy: 0.9246\n",
      "Epoch 137/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0297 - accuracy: 0.9963 - val_loss: 2.7001 - val_accuracy: 0.9232\n",
      "Epoch 138/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9961 - val_loss: 2.9920 - val_accuracy: 0.9239\n",
      "Epoch 139/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0185 - accuracy: 0.9973 - val_loss: 2.7804 - val_accuracy: 0.9279\n",
      "Epoch 140/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0139 - accuracy: 0.9978 - val_loss: 3.3655 - val_accuracy: 0.9206\n",
      "Epoch 141/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 2.9771 - val_accuracy: 0.9252\n",
      "Epoch 142/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 2.7304 - val_accuracy: 0.9292\n",
      "Epoch 143/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9977 - val_loss: 3.2900 - val_accuracy: 0.9232\n",
      "Epoch 144/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 2.9717 - val_accuracy: 0.9239\n",
      "Epoch 145/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.9969 - val_loss: 3.1831 - val_accuracy: 0.9206\n",
      "Epoch 146/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 0.9961 - val_loss: 2.8390 - val_accuracy: 0.9226\n",
      "Epoch 147/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 3.0827 - val_accuracy: 0.9272\n",
      "Epoch 148/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0159 - accuracy: 0.9979 - val_loss: 3.1465 - val_accuracy: 0.9259\n",
      "Epoch 149/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 3.1775 - val_accuracy: 0.9079\n",
      "Epoch 150/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9966 - val_loss: 2.9583 - val_accuracy: 0.9219\n",
      "Epoch 151/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9965 - val_loss: 3.1510 - val_accuracy: 0.9246\n",
      "Epoch 152/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 2.5937 - val_accuracy: 0.9306\n",
      "Epoch 153/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 2.9938 - val_accuracy: 0.9246\n",
      "Epoch 154/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0273 - accuracy: 0.9967 - val_loss: 2.9300 - val_accuracy: 0.9246\n",
      "Epoch 155/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9978 - val_loss: 3.1365 - val_accuracy: 0.9252\n",
      "Epoch 156/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0201 - accuracy: 0.9973 - val_loss: 3.1312 - val_accuracy: 0.9239\n",
      "Epoch 157/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 2.8776 - val_accuracy: 0.9266\n",
      "Epoch 158/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9970 - val_loss: 3.5258 - val_accuracy: 0.9199\n",
      "Epoch 159/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0309 - accuracy: 0.9967 - val_loss: 2.5282 - val_accuracy: 0.9212\n",
      "Epoch 160/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0421 - accuracy: 0.9955 - val_loss: 2.8045 - val_accuracy: 0.9279\n",
      "Epoch 161/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 3.3066 - val_accuracy: 0.9206\n",
      "Epoch 162/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 2.8455 - val_accuracy: 0.9212\n",
      "Epoch 163/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 3.0250 - val_accuracy: 0.9186\n",
      "Epoch 164/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 2.7742 - val_accuracy: 0.9226\n",
      "Epoch 165/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 3.4336 - val_accuracy: 0.9239\n",
      "Epoch 166/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 3.2952 - val_accuracy: 0.9206\n",
      "Epoch 167/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 3.4769 - val_accuracy: 0.9259\n",
      "Epoch 168/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0188 - accuracy: 0.9972 - val_loss: 3.2851 - val_accuracy: 0.9239\n",
      "Epoch 169/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 3.0228 - val_accuracy: 0.9272\n",
      "Epoch 170/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 3.2003 - val_accuracy: 0.9252\n",
      "Epoch 171/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 3.6847 - val_accuracy: 0.9259\n",
      "Epoch 172/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9969 - val_loss: 3.2880 - val_accuracy: 0.9219\n",
      "Epoch 173/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9975 - val_loss: 3.4509 - val_accuracy: 0.9259\n",
      "Epoch 174/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0150 - accuracy: 0.9977 - val_loss: 3.4241 - val_accuracy: 0.9232\n",
      "Epoch 175/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0174 - accuracy: 0.9973 - val_loss: 3.4134 - val_accuracy: 0.9226\n",
      "Epoch 176/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 3.2432 - val_accuracy: 0.9259\n",
      "Epoch 177/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 3.0102 - val_accuracy: 0.9192\n",
      "Epoch 178/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 2.9750 - val_accuracy: 0.9232\n",
      "Epoch 179/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0168 - accuracy: 0.9981 - val_loss: 2.8764 - val_accuracy: 0.9246\n",
      "Epoch 180/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.9979 - val_loss: 3.0213 - val_accuracy: 0.9232\n",
      "Epoch 181/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 3.1473 - val_accuracy: 0.9246\n",
      "Epoch 182/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 3.1684 - val_accuracy: 0.9212\n",
      "Epoch 183/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0183 - accuracy: 0.9977 - val_loss: 3.0752 - val_accuracy: 0.9212\n",
      "Epoch 184/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 2.9465 - val_accuracy: 0.9232\n",
      "Epoch 185/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 3.0408 - val_accuracy: 0.9226\n",
      "Epoch 186/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 2.8515 - val_accuracy: 0.9286\n",
      "Epoch 187/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0178 - accuracy: 0.9979 - val_loss: 3.0263 - val_accuracy: 0.9279\n",
      "Epoch 188/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 3.2583 - val_accuracy: 0.9226\n",
      "Epoch 189/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 3.3489 - val_accuracy: 0.9252\n",
      "Epoch 190/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 3.4691 - val_accuracy: 0.9226\n",
      "Epoch 191/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 3.5191 - val_accuracy: 0.9286\n",
      "Epoch 192/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 3.2534 - val_accuracy: 0.9306\n",
      "Epoch 193/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 3.1547 - val_accuracy: 0.9286\n",
      "Epoch 194/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 3.0264 - val_accuracy: 0.9306\n",
      "Epoch 195/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 3.0456 - val_accuracy: 0.9286\n",
      "Epoch 196/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 3.3422 - val_accuracy: 0.9272\n",
      "Epoch 197/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0136 - accuracy: 0.9984 - val_loss: 3.2811 - val_accuracy: 0.9246\n",
      "Epoch 198/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 3.2351 - val_accuracy: 0.9272\n",
      "Epoch 199/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0121 - accuracy: 0.9984 - val_loss: 3.2328 - val_accuracy: 0.9286\n",
      "Epoch 200/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 3.3462 - val_accuracy: 0.9272\n",
      "Epoch 201/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 2.9035 - val_accuracy: 0.9252\n",
      "Epoch 202/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 3.3427 - val_accuracy: 0.9259\n",
      "Epoch 203/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 3.4964 - val_accuracy: 0.9299\n",
      "Epoch 204/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 3.4709 - val_accuracy: 0.9306\n",
      "Epoch 205/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0160 - accuracy: 0.9977 - val_loss: 3.1187 - val_accuracy: 0.9252\n",
      "Epoch 206/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 3.5088 - val_accuracy: 0.9292\n",
      "Epoch 207/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 3.5781 - val_accuracy: 0.9279\n",
      "Epoch 208/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 3.3993 - val_accuracy: 0.9266\n",
      "Epoch 209/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 3.8380 - val_accuracy: 0.9259\n",
      "Epoch 210/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 4.4868 - val_accuracy: 0.9186\n",
      "Epoch 211/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0178 - accuracy: 0.9976 - val_loss: 2.9814 - val_accuracy: 0.9359\n",
      "Epoch 212/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 3.1993 - val_accuracy: 0.9332\n",
      "Epoch 213/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 3.2802 - val_accuracy: 0.9332\n",
      "Epoch 214/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 3.2239 - val_accuracy: 0.9299\n",
      "Epoch 215/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 3.1729 - val_accuracy: 0.9352\n",
      "Epoch 216/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0144 - accuracy: 0.9984 - val_loss: 3.0871 - val_accuracy: 0.9352\n",
      "Epoch 217/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 3.0769 - val_accuracy: 0.9306\n",
      "Epoch 218/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 3.1968 - val_accuracy: 0.9306\n",
      "Epoch 219/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.9814 - val_accuracy: 0.9366\n",
      "Epoch 220/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 2.8316 - val_accuracy: 0.9312\n",
      "Epoch 221/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 3.0631 - val_accuracy: 0.9306\n",
      "Epoch 222/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 2.8296 - val_accuracy: 0.9352\n",
      "Epoch 223/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.9907 - val_accuracy: 0.9312\n",
      "Epoch 224/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.8927 - val_accuracy: 0.9352\n",
      "Epoch 225/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.7623 - val_accuracy: 0.9346\n",
      "Epoch 226/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 2.9318 - val_accuracy: 0.9319\n",
      "Epoch 227/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 3.0697 - val_accuracy: 0.9326\n",
      "Epoch 228/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 3.1704 - val_accuracy: 0.9359\n",
      "Epoch 229/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 2.9927 - val_accuracy: 0.9312\n",
      "Epoch 230/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 2.8378 - val_accuracy: 0.9346\n",
      "Epoch 231/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 3.0496 - val_accuracy: 0.9312\n",
      "Epoch 232/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 2.9750 - val_accuracy: 0.9306\n",
      "Epoch 233/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 3.3346 - val_accuracy: 0.9306\n",
      "Epoch 234/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 3.6472 - val_accuracy: 0.9286\n",
      "Epoch 235/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 3.3497 - val_accuracy: 0.9319\n",
      "Epoch 236/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0146 - accuracy: 0.9981 - val_loss: 3.7287 - val_accuracy: 0.9259\n",
      "Epoch 237/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0269 - accuracy: 0.9974 - val_loss: 3.5226 - val_accuracy: 0.9232\n",
      "Epoch 238/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 3.7882 - val_accuracy: 0.9266\n",
      "Epoch 239/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 3.4285 - val_accuracy: 0.9286\n",
      "Epoch 240/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 3.1624 - val_accuracy: 0.9352\n",
      "Epoch 241/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 3.1319 - val_accuracy: 0.9326\n",
      "Epoch 242/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9982 - val_loss: 3.4799 - val_accuracy: 0.9299\n",
      "Epoch 243/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0116 - accuracy: 0.9984 - val_loss: 3.6263 - val_accuracy: 0.9339\n",
      "Epoch 244/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 3.2768 - val_accuracy: 0.9259\n",
      "Epoch 245/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 3.3486 - val_accuracy: 0.9319\n",
      "Epoch 246/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 3.2084 - val_accuracy: 0.9259\n",
      "Epoch 247/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 3.1158 - val_accuracy: 0.9239\n",
      "Epoch 248/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 3.1247 - val_accuracy: 0.9259\n",
      "Epoch 249/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 3.1333 - val_accuracy: 0.9292\n",
      "Epoch 250/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 3.5956 - val_accuracy: 0.9286\n",
      "Epoch 251/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 3.4776 - val_accuracy: 0.9286\n",
      "Epoch 252/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 3.3496 - val_accuracy: 0.9279\n",
      "Epoch 253/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 3.4641 - val_accuracy: 0.9232\n",
      "Epoch 254/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 3.3037 - val_accuracy: 0.9326\n",
      "Epoch 255/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 3.5297 - val_accuracy: 0.9286\n",
      "Epoch 256/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 3.1939 - val_accuracy: 0.9286\n",
      "Epoch 257/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 3.2217 - val_accuracy: 0.9306\n",
      "Epoch 258/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 3.2689 - val_accuracy: 0.9299\n",
      "Epoch 259/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.2850 - val_accuracy: 0.9306\n",
      "Epoch 260/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.2921 - val_accuracy: 0.9306\n",
      "Epoch 261/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 3.4510 - val_accuracy: 0.9272\n",
      "Epoch 262/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 3.4871 - val_accuracy: 0.9286\n",
      "Epoch 263/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 3.2727 - val_accuracy: 0.9312\n",
      "Epoch 264/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 3.2848 - val_accuracy: 0.9279\n",
      "Epoch 265/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.2762 - val_accuracy: 0.9279\n",
      "Epoch 266/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 3.3508 - val_accuracy: 0.9312\n",
      "Epoch 267/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 3.3535 - val_accuracy: 0.9319\n",
      "Epoch 268/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.3023 - val_accuracy: 0.9279\n",
      "Epoch 269/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 3.4186 - val_accuracy: 0.9292\n",
      "Epoch 270/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 3.5550 - val_accuracy: 0.9259\n",
      "Epoch 271/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 3.3917 - val_accuracy: 0.9299\n",
      "Epoch 272/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 3.6822 - val_accuracy: 0.9259\n",
      "Epoch 273/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 3.5165 - val_accuracy: 0.9299\n",
      "Epoch 274/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 3.4552 - val_accuracy: 0.9326\n",
      "Epoch 275/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 3.5584 - val_accuracy: 0.9326\n",
      "Epoch 276/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 3.5018 - val_accuracy: 0.9306\n",
      "Epoch 277/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 3.5779 - val_accuracy: 0.9266\n",
      "Epoch 278/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 3.4727 - val_accuracy: 0.9266\n",
      "Epoch 279/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 3.5169 - val_accuracy: 0.9286\n",
      "Epoch 280/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 3.6801 - val_accuracy: 0.9246\n",
      "Epoch 281/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 3.3300 - val_accuracy: 0.9292\n",
      "Epoch 282/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 3.7159 - val_accuracy: 0.9312\n",
      "Epoch 283/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 3.5062 - val_accuracy: 0.9266\n",
      "Epoch 284/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 3.4662 - val_accuracy: 0.9252\n",
      "Epoch 285/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 3.5566 - val_accuracy: 0.9259\n",
      "Epoch 286/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 3.5247 - val_accuracy: 0.9272\n",
      "Epoch 287/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 3.5273 - val_accuracy: 0.9286\n",
      "Epoch 288/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.4759 - val_accuracy: 0.9279\n",
      "Epoch 289/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 3.4274 - val_accuracy: 0.9299\n",
      "Epoch 290/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 3.4376 - val_accuracy: 0.9286\n",
      "Epoch 291/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 3.4338 - val_accuracy: 0.9272\n",
      "Epoch 292/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.4081e-04 - accuracy: 0.9996 - val_loss: 3.5295 - val_accuracy: 0.9272\n",
      "Epoch 293/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 3.5234 - val_accuracy: 0.9266\n",
      "Epoch 294/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.4958 - val_accuracy: 0.9286\n",
      "Epoch 295/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.5705 - val_accuracy: 0.9246\n",
      "Epoch 296/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 3.6927 - val_accuracy: 0.9232\n",
      "Epoch 297/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 3.8845 - val_accuracy: 0.9252\n",
      "Epoch 298/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 3.6755 - val_accuracy: 0.9232\n",
      "Epoch 299/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 3.5940 - val_accuracy: 0.9266\n",
      "Epoch 300/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 3.3801 - val_accuracy: 0.9299\n",
      "Epoch 301/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 3.2626 - val_accuracy: 0.9279\n",
      "Epoch 302/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.2588 - val_accuracy: 0.9312\n",
      "Epoch 303/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.4571e-04 - accuracy: 0.9996 - val_loss: 3.3401 - val_accuracy: 0.9299\n",
      "Epoch 304/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 3.3270 - val_accuracy: 0.9312\n",
      "Epoch 305/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.3544 - val_accuracy: 0.9319\n",
      "Epoch 306/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 3.3031 - val_accuracy: 0.9299\n",
      "Epoch 307/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.3307 - val_accuracy: 0.9312\n",
      "Epoch 308/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.2871 - val_accuracy: 0.9319\n",
      "Epoch 309/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.5330e-04 - accuracy: 0.9996 - val_loss: 3.3104 - val_accuracy: 0.9326\n",
      "Epoch 310/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 3.3754 - val_accuracy: 0.9306\n",
      "Epoch 311/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.9347e-04 - accuracy: 0.9996 - val_loss: 3.3564 - val_accuracy: 0.9306\n",
      "Epoch 312/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.4812e-04 - accuracy: 0.9995 - val_loss: 3.3758 - val_accuracy: 0.9306\n",
      "Epoch 313/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.4047 - val_accuracy: 0.9312\n",
      "Epoch 314/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.3749 - val_accuracy: 0.9319\n",
      "Epoch 315/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 3.3357 - val_accuracy: 0.9339\n",
      "Epoch 316/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 3.3583 - val_accuracy: 0.9299\n",
      "Epoch 317/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 3.3116 - val_accuracy: 0.9306\n",
      "Epoch 318/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.2953 - val_accuracy: 0.9332\n",
      "Epoch 319/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.6256e-04 - accuracy: 0.9996 - val_loss: 3.3789 - val_accuracy: 0.9292\n",
      "Epoch 320/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 3.3276 - val_accuracy: 0.9279\n",
      "Epoch 321/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.3635 - val_accuracy: 0.9286\n",
      "Epoch 322/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 3.3286 - val_accuracy: 0.9292\n",
      "Epoch 323/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 3.3818 - val_accuracy: 0.9286\n",
      "Epoch 324/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 3.3297 - val_accuracy: 0.9292\n",
      "Epoch 325/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.4686e-04 - accuracy: 0.9996 - val_loss: 3.3773 - val_accuracy: 0.9292\n",
      "Epoch 326/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.4976e-04 - accuracy: 0.9996 - val_loss: 3.3222 - val_accuracy: 0.9312\n",
      "Epoch 327/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.6891e-04 - accuracy: 0.9996 - val_loss: 3.3835 - val_accuracy: 0.9312\n",
      "Epoch 328/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.0374e-04 - accuracy: 0.9996 - val_loss: 3.4027 - val_accuracy: 0.9299\n",
      "Epoch 329/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.4037 - val_accuracy: 0.9312\n",
      "Epoch 330/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 3.3591 - val_accuracy: 0.9299\n",
      "Epoch 331/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.3859 - val_accuracy: 0.9286\n",
      "Epoch 332/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 3.3935 - val_accuracy: 0.9286\n",
      "Epoch 333/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.6335e-04 - accuracy: 0.9996 - val_loss: 3.4499 - val_accuracy: 0.9286\n",
      "Epoch 334/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.4561 - val_accuracy: 0.9292\n",
      "Epoch 335/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.4408 - val_accuracy: 0.9299\n",
      "Epoch 336/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.7084e-04 - accuracy: 0.9996 - val_loss: 3.3893 - val_accuracy: 0.9292\n",
      "Epoch 337/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9985e-04 - accuracy: 0.9996 - val_loss: 3.4074 - val_accuracy: 0.9292\n",
      "Epoch 338/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8406e-04 - accuracy: 0.9996 - val_loss: 3.4361 - val_accuracy: 0.9306\n",
      "Epoch 339/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.3790 - val_accuracy: 0.9306\n",
      "Epoch 340/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 3.4055 - val_accuracy: 0.9299\n",
      "Epoch 341/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 3.4008 - val_accuracy: 0.9286\n",
      "Epoch 342/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 3.3670 - val_accuracy: 0.9299\n",
      "Epoch 343/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.3698 - val_accuracy: 0.9299\n",
      "Epoch 344/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8664e-04 - accuracy: 0.9997 - val_loss: 3.3843 - val_accuracy: 0.9299\n",
      "Epoch 345/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9715e-04 - accuracy: 0.9996 - val_loss: 3.3803 - val_accuracy: 0.9299\n",
      "Epoch 346/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.4146 - val_accuracy: 0.9292\n",
      "Epoch 347/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 3.4000 - val_accuracy: 0.9306\n",
      "Epoch 348/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 3.4018 - val_accuracy: 0.9306\n",
      "Epoch 349/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9543e-04 - accuracy: 0.9997 - val_loss: 3.4167 - val_accuracy: 0.9286\n",
      "Epoch 350/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 9.8743e-04 - accuracy: 0.9996 - val_loss: 3.4238 - val_accuracy: 0.9292\n",
      "Epoch 351/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.5521e-04 - accuracy: 0.9996 - val_loss: 3.4229 - val_accuracy: 0.9292\n",
      "Epoch 352/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.4175e-04 - accuracy: 0.9996 - val_loss: 3.4638 - val_accuracy: 0.9292\n",
      "Epoch 353/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 3.4743 - val_accuracy: 0.9279\n",
      "Epoch 354/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9729e-04 - accuracy: 0.9997 - val_loss: 3.4569 - val_accuracy: 0.9286\n",
      "Epoch 355/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.0246e-04 - accuracy: 0.9996 - val_loss: 3.4497 - val_accuracy: 0.9286\n",
      "Epoch 356/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.4910e-04 - accuracy: 0.9996 - val_loss: 3.4619 - val_accuracy: 0.9279\n",
      "Epoch 357/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3939e-04 - accuracy: 0.9997 - val_loss: 3.4698 - val_accuracy: 0.9272\n",
      "Epoch 358/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0366e-04 - accuracy: 0.9996 - val_loss: 3.4703 - val_accuracy: 0.9272\n",
      "Epoch 359/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1148e-04 - accuracy: 0.9996 - val_loss: 3.4776 - val_accuracy: 0.9272\n",
      "Epoch 360/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 6.9498e-04 - accuracy: 0.9996 - val_loss: 3.4791 - val_accuracy: 0.9266\n",
      "Epoch 361/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.0859e-04 - accuracy: 0.9996 - val_loss: 3.4886 - val_accuracy: 0.9266\n",
      "Epoch 362/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.6440e-04 - accuracy: 0.9996 - val_loss: 3.5059 - val_accuracy: 0.9279\n",
      "Epoch 363/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1374e-04 - accuracy: 0.9997 - val_loss: 3.5131 - val_accuracy: 0.9272\n",
      "Epoch 364/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 8.1252e-04 - accuracy: 0.9997 - val_loss: 3.5246 - val_accuracy: 0.9272\n",
      "Epoch 365/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 6.7484e-04 - accuracy: 0.9997 - val_loss: 3.4846 - val_accuracy: 0.9266\n",
      "Epoch 366/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1583e-04 - accuracy: 0.9997 - val_loss: 3.4997 - val_accuracy: 0.9266\n",
      "Epoch 367/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9216e-04 - accuracy: 0.9997 - val_loss: 3.5033 - val_accuracy: 0.9272\n",
      "Epoch 368/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0594e-04 - accuracy: 0.9996 - val_loss: 3.5088 - val_accuracy: 0.9272\n",
      "Epoch 369/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0112e-04 - accuracy: 0.9996 - val_loss: 3.5315 - val_accuracy: 0.9272\n",
      "Epoch 370/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.3015e-04 - accuracy: 0.9997 - val_loss: 3.4973 - val_accuracy: 0.9252\n",
      "Epoch 371/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5701e-04 - accuracy: 0.9996 - val_loss: 3.5143 - val_accuracy: 0.9266\n",
      "Epoch 372/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1431e-04 - accuracy: 0.9996 - val_loss: 3.5218 - val_accuracy: 0.9266\n",
      "Epoch 373/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.2192e-04 - accuracy: 0.9997 - val_loss: 3.4809 - val_accuracy: 0.9266\n",
      "Epoch 374/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0787e-04 - accuracy: 0.9997 - val_loss: 3.4833 - val_accuracy: 0.9272\n",
      "Epoch 375/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9358e-04 - accuracy: 0.9996 - val_loss: 3.4830 - val_accuracy: 0.9272\n",
      "Epoch 376/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0098e-04 - accuracy: 0.9996 - val_loss: 3.4870 - val_accuracy: 0.9279\n",
      "Epoch 377/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0820e-04 - accuracy: 0.9996 - val_loss: 3.4974 - val_accuracy: 0.9272\n",
      "Epoch 378/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0269e-04 - accuracy: 0.9996 - val_loss: 3.5085 - val_accuracy: 0.9266\n",
      "Epoch 379/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3854e-04 - accuracy: 0.9996 - val_loss: 3.5116 - val_accuracy: 0.9272\n",
      "Epoch 380/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9203e-04 - accuracy: 0.9996 - val_loss: 3.5055 - val_accuracy: 0.9272\n",
      "Epoch 381/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9875e-04 - accuracy: 0.9996 - val_loss: 3.5146 - val_accuracy: 0.9272\n",
      "Epoch 382/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.1109e-04 - accuracy: 0.9996 - val_loss: 3.5209 - val_accuracy: 0.9266\n",
      "Epoch 383/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0199e-04 - accuracy: 0.9997 - val_loss: 3.5353 - val_accuracy: 0.9266\n",
      "Epoch 384/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9871e-04 - accuracy: 0.9997 - val_loss: 3.5440 - val_accuracy: 0.9266\n",
      "Epoch 385/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.5559e-04 - accuracy: 0.9996 - val_loss: 3.5632 - val_accuracy: 0.9266\n",
      "Epoch 386/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1840e-04 - accuracy: 0.9996 - val_loss: 3.5652 - val_accuracy: 0.9266\n",
      "Epoch 387/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0831e-04 - accuracy: 0.9996 - val_loss: 3.5740 - val_accuracy: 0.9259\n",
      "Epoch 388/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.0153e-04 - accuracy: 0.9996 - val_loss: 3.5803 - val_accuracy: 0.9252\n",
      "Epoch 389/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 7.0277e-04 - accuracy: 0.9996 - val_loss: 3.5839 - val_accuracy: 0.9252\n",
      "Epoch 390/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9494e-04 - accuracy: 0.9996 - val_loss: 3.5865 - val_accuracy: 0.9252\n",
      "Epoch 391/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8960e-04 - accuracy: 0.9996 - val_loss: 3.5899 - val_accuracy: 0.9252\n",
      "Epoch 392/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9792e-04 - accuracy: 0.9996 - val_loss: 3.6008 - val_accuracy: 0.9252\n",
      "Epoch 393/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9544e-04 - accuracy: 0.9996 - val_loss: 3.5996 - val_accuracy: 0.9252\n",
      "Epoch 394/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.8017e-04 - accuracy: 0.9996 - val_loss: 3.6076 - val_accuracy: 0.9252\n",
      "Epoch 395/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.6660e-04 - accuracy: 0.9996 - val_loss: 3.5722 - val_accuracy: 0.9246\n",
      "Epoch 396/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.6996e-04 - accuracy: 0.9996 - val_loss: 3.5944 - val_accuracy: 0.9239\n",
      "Epoch 397/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.3949e-04 - accuracy: 0.9996 - val_loss: 3.5718 - val_accuracy: 0.9252\n",
      "Epoch 398/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.5914e-04 - accuracy: 0.9996 - val_loss: 3.5746 - val_accuracy: 0.9272\n",
      "Epoch 399/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.8848e-04 - accuracy: 0.9996 - val_loss: 3.5479 - val_accuracy: 0.9272\n",
      "Epoch 400/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6687e-04 - accuracy: 0.9996 - val_loss: 3.5348 - val_accuracy: 0.9246\n",
      "Epoch 401/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.4108e-04 - accuracy: 0.9996 - val_loss: 3.5301 - val_accuracy: 0.9259\n",
      "Epoch 402/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1854e-04 - accuracy: 0.9997 - val_loss: 3.5310 - val_accuracy: 0.9259\n",
      "Epoch 403/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8594e-04 - accuracy: 0.9996 - val_loss: 3.5337 - val_accuracy: 0.9279\n",
      "Epoch 404/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.4149e-04 - accuracy: 0.9996 - val_loss: 3.5681 - val_accuracy: 0.9259\n",
      "Epoch 405/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5529e-04 - accuracy: 0.9996 - val_loss: 3.5405 - val_accuracy: 0.9259\n",
      "Epoch 406/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0779e-04 - accuracy: 0.9996 - val_loss: 3.5478 - val_accuracy: 0.9252\n",
      "Epoch 407/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0070e-04 - accuracy: 0.9996 - val_loss: 3.5458 - val_accuracy: 0.9252\n",
      "Epoch 408/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9473e-04 - accuracy: 0.9996 - val_loss: 3.5532 - val_accuracy: 0.9252\n",
      "Epoch 409/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0243e-04 - accuracy: 0.9996 - val_loss: 3.5619 - val_accuracy: 0.9252\n",
      "Epoch 410/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8712e-04 - accuracy: 0.9996 - val_loss: 3.5632 - val_accuracy: 0.9252\n",
      "Epoch 411/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9463e-04 - accuracy: 0.9996 - val_loss: 3.5700 - val_accuracy: 0.9246\n",
      "Epoch 412/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9016e-04 - accuracy: 0.9996 - val_loss: 3.5772 - val_accuracy: 0.9252\n",
      "Epoch 413/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9705e-04 - accuracy: 0.9996 - val_loss: 3.5825 - val_accuracy: 0.9252\n",
      "Epoch 414/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9676e-04 - accuracy: 0.9997 - val_loss: 3.5963 - val_accuracy: 0.9252\n",
      "Epoch 415/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8884e-04 - accuracy: 0.9996 - val_loss: 3.5965 - val_accuracy: 0.9252\n",
      "Epoch 416/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8958e-04 - accuracy: 0.9996 - val_loss: 3.5999 - val_accuracy: 0.9246\n",
      "Epoch 417/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8425e-04 - accuracy: 0.9996 - val_loss: 3.6012 - val_accuracy: 0.9246\n",
      "Epoch 418/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 6.9370e-04 - accuracy: 0.9996 - val_loss: 3.6076 - val_accuracy: 0.9252\n",
      "Epoch 419/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 6.9146e-04 - accuracy: 0.9996 - val_loss: 3.6114 - val_accuracy: 0.9252\n",
      "Epoch 420/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9592e-04 - accuracy: 0.9997 - val_loss: 3.6175 - val_accuracy: 0.9246\n",
      "Epoch 421/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9278e-04 - accuracy: 0.9997 - val_loss: 3.6214 - val_accuracy: 0.9246\n",
      "Epoch 422/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9943e-04 - accuracy: 0.9996 - val_loss: 3.5992 - val_accuracy: 0.9246\n",
      "Epoch 423/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8858e-04 - accuracy: 0.9996 - val_loss: 3.6058 - val_accuracy: 0.9239\n",
      "Epoch 424/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8638e-04 - accuracy: 0.9996 - val_loss: 3.6113 - val_accuracy: 0.9239\n",
      "Epoch 425/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9047e-04 - accuracy: 0.9996 - val_loss: 3.6148 - val_accuracy: 0.9239\n",
      "Epoch 426/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8706e-04 - accuracy: 0.9997 - val_loss: 3.6176 - val_accuracy: 0.9239\n",
      "Epoch 427/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8780e-04 - accuracy: 0.9997 - val_loss: 3.6200 - val_accuracy: 0.9239\n",
      "Epoch 428/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.7778e-04 - accuracy: 0.9996 - val_loss: 3.6149 - val_accuracy: 0.9239\n",
      "Epoch 429/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9480e-04 - accuracy: 0.9996 - val_loss: 3.6171 - val_accuracy: 0.9239\n",
      "Epoch 430/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.7972e-04 - accuracy: 0.9996 - val_loss: 3.6209 - val_accuracy: 0.9239\n",
      "Epoch 431/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8624e-04 - accuracy: 0.9996 - val_loss: 3.6240 - val_accuracy: 0.9239\n",
      "Epoch 432/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9678e-04 - accuracy: 0.9997 - val_loss: 3.6312 - val_accuracy: 0.9239\n",
      "Epoch 433/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9146e-04 - accuracy: 0.9997 - val_loss: 3.6355 - val_accuracy: 0.9239\n",
      "Epoch 434/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.7112e-04 - accuracy: 0.9996 - val_loss: 3.6255 - val_accuracy: 0.9239\n",
      "Epoch 435/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9130e-04 - accuracy: 0.9996 - val_loss: 3.6335 - val_accuracy: 0.9239\n",
      "Epoch 436/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9691e-04 - accuracy: 0.9996 - val_loss: 3.6406 - val_accuracy: 0.9239\n",
      "Epoch 437/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0175e-04 - accuracy: 0.9997 - val_loss: 3.6594 - val_accuracy: 0.9246\n",
      "Epoch 438/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8944e-04 - accuracy: 0.9996 - val_loss: 3.6598 - val_accuracy: 0.9246\n",
      "Epoch 439/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8828e-04 - accuracy: 0.9997 - val_loss: 3.6626 - val_accuracy: 0.9246\n",
      "Epoch 440/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9432e-04 - accuracy: 0.9996 - val_loss: 3.6674 - val_accuracy: 0.9246\n",
      "Epoch 441/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9946e-04 - accuracy: 0.9996 - val_loss: 3.6679 - val_accuracy: 0.9246\n",
      "Epoch 442/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9317e-04 - accuracy: 0.9996 - val_loss: 3.6666 - val_accuracy: 0.9246\n",
      "Epoch 443/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8739e-04 - accuracy: 0.9996 - val_loss: 3.6676 - val_accuracy: 0.9246\n",
      "Epoch 444/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8313e-04 - accuracy: 0.9997 - val_loss: 3.6673 - val_accuracy: 0.9246\n",
      "Epoch 445/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9012e-04 - accuracy: 0.9996 - val_loss: 3.6754 - val_accuracy: 0.9246\n",
      "Epoch 446/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.9054e-04 - accuracy: 0.9996 - val_loss: 3.6679 - val_accuracy: 0.9252\n",
      "Epoch 447/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 7.3404e-04 - accuracy: 0.9996 - val_loss: 3.6652 - val_accuracy: 0.9246\n",
      "Epoch 448/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 6.9887e-04 - accuracy: 0.9996 - val_loss: 3.6536 - val_accuracy: 0.9252\n",
      "Epoch 449/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9426e-04 - accuracy: 0.9996 - val_loss: 3.6656 - val_accuracy: 0.9246\n",
      "Epoch 450/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9293e-04 - accuracy: 0.9996 - val_loss: 3.6708 - val_accuracy: 0.9252\n",
      "Epoch 451/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9128e-04 - accuracy: 0.9996 - val_loss: 3.6776 - val_accuracy: 0.9246\n",
      "Epoch 452/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8234e-04 - accuracy: 0.9997 - val_loss: 3.6781 - val_accuracy: 0.9252\n",
      "Epoch 453/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0661e-04 - accuracy: 0.9997 - val_loss: 3.6762 - val_accuracy: 0.9252\n",
      "Epoch 454/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8765e-04 - accuracy: 0.9996 - val_loss: 3.6744 - val_accuracy: 0.9252\n",
      "Epoch 455/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9270e-04 - accuracy: 0.9997 - val_loss: 3.6802 - val_accuracy: 0.9252\n",
      "Epoch 456/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8645e-04 - accuracy: 0.9996 - val_loss: 3.6829 - val_accuracy: 0.9252\n",
      "Epoch 457/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8085e-04 - accuracy: 0.9996 - val_loss: 3.6781 - val_accuracy: 0.9252\n",
      "Epoch 458/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8428e-04 - accuracy: 0.9997 - val_loss: 3.6833 - val_accuracy: 0.9252\n",
      "Epoch 459/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9637e-04 - accuracy: 0.9996 - val_loss: 3.6831 - val_accuracy: 0.9246\n",
      "Epoch 460/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8658e-04 - accuracy: 0.9996 - val_loss: 3.6821 - val_accuracy: 0.9246\n",
      "Epoch 461/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8952e-04 - accuracy: 0.9997 - val_loss: 3.6904 - val_accuracy: 0.9246\n",
      "Epoch 462/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8886e-04 - accuracy: 0.9996 - val_loss: 3.6924 - val_accuracy: 0.9239\n",
      "Epoch 463/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0395e-04 - accuracy: 0.9997 - val_loss: 3.6814 - val_accuracy: 0.9252\n",
      "Epoch 464/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8932e-04 - accuracy: 0.9997 - val_loss: 3.6977 - val_accuracy: 0.9246\n",
      "Epoch 465/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8906e-04 - accuracy: 0.9997 - val_loss: 3.6960 - val_accuracy: 0.9252\n",
      "Epoch 466/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8411e-04 - accuracy: 0.9996 - val_loss: 3.6990 - val_accuracy: 0.9246\n",
      "Epoch 467/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9386e-04 - accuracy: 0.9996 - val_loss: 3.7118 - val_accuracy: 0.9239\n",
      "Epoch 468/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9473e-04 - accuracy: 0.9997 - val_loss: 3.7096 - val_accuracy: 0.9246\n",
      "Epoch 469/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9040e-04 - accuracy: 0.9996 - val_loss: 3.7135 - val_accuracy: 0.9246\n",
      "Epoch 470/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8574e-04 - accuracy: 0.9996 - val_loss: 3.7094 - val_accuracy: 0.9232\n",
      "Epoch 471/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8386e-04 - accuracy: 0.9996 - val_loss: 3.7196 - val_accuracy: 0.9239\n",
      "Epoch 472/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8909e-04 - accuracy: 0.9996 - val_loss: 3.7351 - val_accuracy: 0.9232\n",
      "Epoch 473/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8833e-04 - accuracy: 0.9996 - val_loss: 3.7411 - val_accuracy: 0.9232\n",
      "Epoch 474/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8866e-04 - accuracy: 0.9996 - val_loss: 3.7476 - val_accuracy: 0.9226\n",
      "Epoch 475/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8705e-04 - accuracy: 0.9997 - val_loss: 3.7493 - val_accuracy: 0.9232\n",
      "Epoch 476/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 6.7908e-04 - accuracy: 0.9996 - val_loss: 3.7543 - val_accuracy: 0.9232\n",
      "Epoch 477/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 6.7364e-04 - accuracy: 0.9996 - val_loss: 3.7497 - val_accuracy: 0.9239\n",
      "Epoch 478/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.7778e-04 - accuracy: 0.9996 - val_loss: 3.7538 - val_accuracy: 0.9239\n",
      "Epoch 479/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.7277e-04 - accuracy: 0.9996 - val_loss: 3.7596 - val_accuracy: 0.9239\n",
      "Epoch 480/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.7952e-04 - accuracy: 0.9996 - val_loss: 3.7633 - val_accuracy: 0.9239\n",
      "Epoch 481/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8333e-04 - accuracy: 0.9997 - val_loss: 3.7702 - val_accuracy: 0.9232\n",
      "Epoch 482/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.6881e-04 - accuracy: 0.9996 - val_loss: 3.7406 - val_accuracy: 0.9259\n",
      "Epoch 483/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 3.7239 - val_accuracy: 0.9246\n",
      "Epoch 484/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 8.6349e-04 - accuracy: 0.9997 - val_loss: 3.6905 - val_accuracy: 0.9252\n",
      "Epoch 485/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 3.4699 - val_accuracy: 0.9306\n",
      "Epoch 486/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 3.8082 - val_accuracy: 0.9286\n",
      "Epoch 487/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 3.7184 - val_accuracy: 0.9259\n",
      "Epoch 488/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 3.7291 - val_accuracy: 0.9272\n",
      "Epoch 489/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 4.1347 - val_accuracy: 0.9286\n",
      "Epoch 490/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 3.9555 - val_accuracy: 0.9326\n",
      "Epoch 491/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 3.9735 - val_accuracy: 0.9286\n",
      "Epoch 492/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 4.2039 - val_accuracy: 0.9259\n",
      "Epoch 493/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 3.9586 - val_accuracy: 0.9279\n",
      "Epoch 494/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 4.0206 - val_accuracy: 0.9312\n",
      "Epoch 495/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 4.2071 - val_accuracy: 0.9299\n",
      "Epoch 496/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 4.0301 - val_accuracy: 0.9299\n",
      "Epoch 497/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.6796e-04 - accuracy: 0.9996 - val_loss: 4.0181 - val_accuracy: 0.9306\n",
      "Epoch 498/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.7759e-04 - accuracy: 0.9997 - val_loss: 4.0131 - val_accuracy: 0.9299\n",
      "Epoch 499/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1456e-04 - accuracy: 0.9997 - val_loss: 4.0127 - val_accuracy: 0.9306\n",
      "Epoch 500/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1836e-04 - accuracy: 0.9996 - val_loss: 4.0211 - val_accuracy: 0.9312\n",
      "Epoch 501/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.4814e-04 - accuracy: 0.9996 - val_loss: 4.0258 - val_accuracy: 0.9299\n",
      "Epoch 502/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.2955e-04 - accuracy: 0.9996 - val_loss: 4.0422 - val_accuracy: 0.9306\n",
      "Epoch 503/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.3025e-04 - accuracy: 0.9996 - val_loss: 4.0190 - val_accuracy: 0.9299\n",
      "Epoch 504/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 6.9796e-04 - accuracy: 0.9996 - val_loss: 4.0224 - val_accuracy: 0.9306\n",
      "Epoch 505/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 7.4782e-04 - accuracy: 0.9996 - val_loss: 4.0275 - val_accuracy: 0.9292\n",
      "Epoch 506/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0628e-04 - accuracy: 0.9996 - val_loss: 4.0137 - val_accuracy: 0.9299\n",
      "Epoch 507/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.1471e-04 - accuracy: 0.9997 - val_loss: 4.0255 - val_accuracy: 0.9312\n",
      "Epoch 508/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.9841e-04 - accuracy: 0.9996 - val_loss: 4.0667 - val_accuracy: 0.9306\n",
      "Epoch 509/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.7348e-04 - accuracy: 0.9996 - val_loss: 4.0371 - val_accuracy: 0.9306\n",
      "Epoch 510/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.2806e-04 - accuracy: 0.9997 - val_loss: 4.0416 - val_accuracy: 0.9292\n",
      "Epoch 511/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1473e-04 - accuracy: 0.9996 - val_loss: 4.0387 - val_accuracy: 0.9299\n",
      "Epoch 512/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1816e-04 - accuracy: 0.9996 - val_loss: 4.0373 - val_accuracy: 0.9299\n",
      "Epoch 513/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0592e-04 - accuracy: 0.9996 - val_loss: 4.0536 - val_accuracy: 0.9299\n",
      "Epoch 514/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8528e-04 - accuracy: 0.9997 - val_loss: 4.0437 - val_accuracy: 0.9299\n",
      "Epoch 515/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9897e-04 - accuracy: 0.9996 - val_loss: 4.0536 - val_accuracy: 0.9299\n",
      "Epoch 516/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0479e-04 - accuracy: 0.9996 - val_loss: 4.0457 - val_accuracy: 0.9299\n",
      "Epoch 517/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0214e-04 - accuracy: 0.9997 - val_loss: 4.0564 - val_accuracy: 0.9299\n",
      "Epoch 518/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0209e-04 - accuracy: 0.9997 - val_loss: 4.0620 - val_accuracy: 0.9299\n",
      "Epoch 519/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0087e-04 - accuracy: 0.9996 - val_loss: 4.0671 - val_accuracy: 0.9299\n",
      "Epoch 520/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5703e-04 - accuracy: 0.9997 - val_loss: 4.0684 - val_accuracy: 0.9292\n",
      "Epoch 521/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3717e-04 - accuracy: 0.9997 - val_loss: 4.0470 - val_accuracy: 0.9299\n",
      "Epoch 522/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9730e-04 - accuracy: 0.9996 - val_loss: 4.0471 - val_accuracy: 0.9299\n",
      "Epoch 523/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0063e-04 - accuracy: 0.9997 - val_loss: 4.0554 - val_accuracy: 0.9299\n",
      "Epoch 524/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.9593e-04 - accuracy: 0.9996 - val_loss: 4.0648 - val_accuracy: 0.9292\n",
      "Epoch 525/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8906e-04 - accuracy: 0.9996 - val_loss: 4.0571 - val_accuracy: 0.9299\n",
      "Epoch 526/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 6.8445e-04 - accuracy: 0.9997 - val_loss: 4.0697 - val_accuracy: 0.9299\n",
      "Epoch 527/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1061e-04 - accuracy: 0.9996 - val_loss: 4.0769 - val_accuracy: 0.9286\n",
      "Epoch 528/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.0491e-04 - accuracy: 0.9997 - val_loss: 4.0721 - val_accuracy: 0.9292\n",
      "Epoch 529/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.9325e-04 - accuracy: 0.9997 - val_loss: 4.0718 - val_accuracy: 0.9292\n",
      "Epoch 530/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 6.8884e-04 - accuracy: 0.9996 - val_loss: 4.0687 - val_accuracy: 0.9292\n",
      "Epoch 531/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8251e-04 - accuracy: 0.9997 - val_loss: 4.0321 - val_accuracy: 0.9286\n",
      "Epoch 532/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 8.7199e-04 - accuracy: 0.9996 - val_loss: 4.0379 - val_accuracy: 0.9286\n",
      "Epoch 533/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 8.0813e-04 - accuracy: 0.9996 - val_loss: 4.0635 - val_accuracy: 0.9299\n",
      "Epoch 534/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5633e-04 - accuracy: 0.9996 - val_loss: 4.0725 - val_accuracy: 0.9279\n",
      "Epoch 535/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3538e-04 - accuracy: 0.9996 - val_loss: 4.0624 - val_accuracy: 0.9286\n",
      "Epoch 536/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1957e-04 - accuracy: 0.9996 - val_loss: 4.0574 - val_accuracy: 0.9286\n",
      "Epoch 537/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.2038e-04 - accuracy: 0.9996 - val_loss: 4.0439 - val_accuracy: 0.9279\n",
      "Epoch 538/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.4121e-04 - accuracy: 0.9997 - val_loss: 4.0597 - val_accuracy: 0.9292\n",
      "Epoch 539/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.2073e-04 - accuracy: 0.9996 - val_loss: 4.0395 - val_accuracy: 0.9272\n",
      "Epoch 540/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3033e-04 - accuracy: 0.9997 - val_loss: 4.0463 - val_accuracy: 0.9286\n",
      "Epoch 541/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.1467e-04 - accuracy: 0.9996 - val_loss: 4.0654 - val_accuracy: 0.9279\n",
      "Epoch 542/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.1864e-04 - accuracy: 0.9996 - val_loss: 4.0363 - val_accuracy: 0.9299\n",
      "Epoch 543/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.9965e-04 - accuracy: 0.9996 - val_loss: 3.9588 - val_accuracy: 0.9246\n",
      "Epoch 807/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6730e-04 - accuracy: 0.9996 - val_loss: 3.9593 - val_accuracy: 0.9239\n",
      "Epoch 808/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6178e-04 - accuracy: 0.9996 - val_loss: 3.9560 - val_accuracy: 0.9239\n",
      "Epoch 809/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.9902e-04 - accuracy: 0.9996 - val_loss: 3.9801 - val_accuracy: 0.9239\n",
      "Epoch 810/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.9717e-04 - accuracy: 0.9996 - val_loss: 3.9674 - val_accuracy: 0.9239\n",
      "Epoch 811/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.0561e-04 - accuracy: 0.9997 - val_loss: 3.9775 - val_accuracy: 0.9232\n",
      "Epoch 812/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.7180e-04 - accuracy: 0.9996 - val_loss: 3.9843 - val_accuracy: 0.9232\n",
      "Epoch 813/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.7026e-04 - accuracy: 0.9996 - val_loss: 3.9749 - val_accuracy: 0.9239\n",
      "Epoch 814/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.0045e-04 - accuracy: 0.9996 - val_loss: 3.9802 - val_accuracy: 0.9239\n",
      "Epoch 815/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3533e-04 - accuracy: 0.9996 - val_loss: 3.9900 - val_accuracy: 0.9239\n",
      "Epoch 816/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8679e-04 - accuracy: 0.9997 - val_loss: 3.9912 - val_accuracy: 0.9232\n",
      "Epoch 817/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 7.6246e-04 - accuracy: 0.9996 - val_loss: 3.9939 - val_accuracy: 0.9232\n",
      "Epoch 818/1000\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 7.7975e-04 - accuracy: 0.9997 - val_loss: 4.0010 - val_accuracy: 0.9232\n",
      "Epoch 819/1000\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 7.4479e-04 - accuracy: 0.9996 - val_loss: 4.0255 - val_accuracy: 0.9226\n",
      "Epoch 820/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.4668e-04 - accuracy: 0.9996 - val_loss: 3.9967 - val_accuracy: 0.9232\n",
      "Epoch 821/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5585e-04 - accuracy: 0.9996 - val_loss: 3.9884 - val_accuracy: 0.9232\n",
      "Epoch 822/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8409e-04 - accuracy: 0.9996 - val_loss: 3.9947 - val_accuracy: 0.9232\n",
      "Epoch 823/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.4990e-04 - accuracy: 0.9996 - val_loss: 3.9823 - val_accuracy: 0.9226\n",
      "Epoch 824/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8851e-04 - accuracy: 0.9996 - val_loss: 3.9834 - val_accuracy: 0.9232\n",
      "Epoch 825/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.9626e-04 - accuracy: 0.9996 - val_loss: 3.9873 - val_accuracy: 0.9232\n",
      "Epoch 826/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.7647e-04 - accuracy: 0.9996 - val_loss: 3.9836 - val_accuracy: 0.9232\n",
      "Epoch 827/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.4493e-04 - accuracy: 0.9996 - val_loss: 3.9842 - val_accuracy: 0.9232\n",
      "Epoch 828/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5654e-04 - accuracy: 0.9996 - val_loss: 3.9904 - val_accuracy: 0.9232\n",
      "Epoch 829/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8727e-04 - accuracy: 0.9997 - val_loss: 3.9884 - val_accuracy: 0.9232\n",
      "Epoch 830/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3278e-04 - accuracy: 0.9997 - val_loss: 3.9948 - val_accuracy: 0.9232\n",
      "Epoch 831/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5355e-04 - accuracy: 0.9996 - val_loss: 4.0016 - val_accuracy: 0.9226\n",
      "Epoch 832/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6919e-04 - accuracy: 0.9996 - val_loss: 4.0025 - val_accuracy: 0.9232\n",
      "Epoch 833/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3966e-04 - accuracy: 0.9997 - val_loss: 4.0173 - val_accuracy: 0.9232\n",
      "Epoch 834/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6546e-04 - accuracy: 0.9997 - val_loss: 4.0120 - val_accuracy: 0.9239\n",
      "Epoch 835/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.1468e-04 - accuracy: 0.9996 - val_loss: 4.0127 - val_accuracy: 0.9239\n",
      "Epoch 836/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.8572e-04 - accuracy: 0.9996 - val_loss: 4.0243 - val_accuracy: 0.9239\n",
      "Epoch 837/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.5230e-04 - accuracy: 0.9997 - val_loss: 4.0287 - val_accuracy: 0.9232\n",
      "Epoch 838/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6601e-04 - accuracy: 0.9996 - val_loss: 4.0379 - val_accuracy: 0.9226\n",
      "Epoch 839/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6020e-04 - accuracy: 0.9996 - val_loss: 4.0418 - val_accuracy: 0.9232\n",
      "Epoch 840/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6688e-04 - accuracy: 0.9996 - val_loss: 4.0567 - val_accuracy: 0.9226\n",
      "Epoch 841/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.3869e-04 - accuracy: 0.9996 - val_loss: 4.0702 - val_accuracy: 0.9226\n",
      "Epoch 842/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.0910 - val_accuracy: 0.9239\n",
      "Epoch 843/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.7332e-04 - accuracy: 0.9997 - val_loss: 4.0912 - val_accuracy: 0.9232\n",
      "Epoch 844/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 4.0991 - val_accuracy: 0.9232\n",
      "Epoch 845/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 4.0953 - val_accuracy: 0.9232\n",
      "Epoch 846/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 8.1070e-04 - accuracy: 0.9996 - val_loss: 3.9863 - val_accuracy: 0.9272\n",
      "Epoch 906/1000\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 8.3563e-04 - accuracy: 0.9996 - val_loss: 3.9816 - val_accuracy: 0.9272\n",
      "Epoch 907/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.7696e-04 - accuracy: 0.9996 - val_loss: 3.9921 - val_accuracy: 0.9266\n",
      "Epoch 908/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.2772e-04 - accuracy: 0.9996 - val_loss: 4.0170 - val_accuracy: 0.9272\n",
      "Epoch 909/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.6132e-04 - accuracy: 0.9996 - val_loss: 4.0180 - val_accuracy: 0.9272\n",
      "Epoch 910/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 7.7899e-04 - accuracy: 0.9996 - val_loss: 3.9944 - val_accuracy: 0.9272\n",
      "Epoch 911/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.1390e-04 - accuracy: 0.9997 - val_loss: 4.0158 - val_accuracy: 0.9292\n",
      "Epoch 912/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.4651e-04 - accuracy: 0.9997 - val_loss: 3.9885 - val_accuracy: 0.9286\n",
      "Epoch 913/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 8.0124e-04 - accuracy: 0.9996 - val_loss: 3.9825 - val_accuracy: 0.9292\n",
      "Epoch 914/1000\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 9.5448e-04 - accuracy: 0.9996 - val_loss: 4.0687 - val_accuracy: 0.9292\n",
      "Epoch 915/1000\n",
      "378/422 [=========================>....] - ETA: 0s - loss: 0.0053 - accuracy: 0.9990"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train,y_train,epochs=1000,validation_split=0.1)\n",
    "test_loss,test_acc=model.evaluate(X_test,y_test)\n",
    "print(\"Test Accurracy \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ef24e-c242-4c3c-b314-0b6e05dbf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation graph for over & underfitting analysis\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c49fe-0c13-4fe4-b37c-69fd5a0b7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses \n",
    "from keras import optimizers \n",
    "from keras import metrics \n",
    "from keras.layers import Dense, Dropout \n",
    "from keras.optimizers import RMSprop ,Adam,SGD,Adagrad,Adadelta,Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8234be-5877-49f8-bbb9-2132415c36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dense(64, activation=\"softmax\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74511a-d797-4e5c-be11-e1495140c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',     \n",
    "   optimizer = Adam(learning_rate = 0.001), \n",
    "   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1dda4-217e-4594-a59a-f48f77d3d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "   X_train, y_train, \n",
    "   batch_size = 128, \n",
    "   epochs = 1000, \n",
    "   verbose = 1, \n",
    "   validation_data = (X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f756895-d79c-4252-ba8d-4fe5686c6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy\n",
    "(eval_loss, eval_accuracy) = model.evaluate(X_test,y_test, verbose=1)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88046da8-4136-42a8-bb5d-370ed4db681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation graph for over & underfitting analysis\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509d9f4-ef10-4920-bf1c-a31cdfde7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses \n",
    "from keras import optimizers \n",
    "from keras import metrics \n",
    "from keras.layers import Dense, Dropout \n",
    "from keras.optimizers import RMSprop ,Adam,SGD,Adagrad,Adadelta,Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ebd9a-70fb-4669-baf6-834d5da70346",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "#model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf06abd-5c75-47c4-aa09-433b156fd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',     \n",
    "   optimizer = Adam(learning_rate = 0.001), \n",
    "   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0791f-7109-4d31-8080-6bd8deb211b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model_name = \"Soumen.h5\"\n",
    "# Checkpoint Callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_name, monitor='val_loss', verbose=2, save_best_only=True, mode='auto')\n",
    "\n",
    "# EarlyStopping Callback\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                      patience=15, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344345d-9af3-44f1-9cdf-f9d29f1d113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "   X_train, y_train, \n",
    "   batch_size = 128, \n",
    "   epochs = 1000, \n",
    "   verbose = 1, \n",
    "   validation_data = (X_test, y_test),\n",
    "   callbacks=[checkpoint, early],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57849-0dcb-4299-aa39-eac8ac1b8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLoaded = tf.keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3280a-e6a1-451e-b23d-a51ccb53862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelLoaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22f8fb-2743-4a81-9bb2-ac4132afdce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy\n",
    "(eval_loss, eval_accuracy) = model.evaluate(X_test,y_test, verbose=1)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c55b4-db6d-4241-aaf1-e9032124d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation graph for over & underfitting analysis\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b34d2-e0a0-473d-9e62-a9fd743bd1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
